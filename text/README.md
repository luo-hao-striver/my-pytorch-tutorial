# 1. NLP的处理
- 整个语言模型的感悟
  1. 一般通过预处理，解决停用词、网络词（URL）、不相关符号等
     - 如：'I Love China'
  2. 利用分词器（token）将每句话的词分开
     - 如：['I', 'Love', 'China'] 
  3. 建立词表，将符号变为数值
     - 如：{'I': 0, 'Love': 1, 'China': 2} 
  4. 传统方法是one-hot方法
     - 如： 'I Love China'表示为'''[[1, 0, 0], [0, 1, 0],[0, 0, 1]]'''
  5. 上述方法太冗余，对大量的词句不适合，解决办法：
     - 有word2vec、glove、fasttext等**静态词向量模型**
     - 有bert，GPT等**动态词向量模型**
  6. 映射好以后，就可以按照特定任务实施

# 2. 词向量的方式
- 作者认为，词向量有两种方式
  1. 传统上的词向量：通过embedding层训练词向量，输入是以词表方式建立的数值，而每个'数值'词的映射向量构成输出
  2. 较热门的：将词向量看作单独的模型，有静态词向量word2vec、glove、fasttext等，也有动态的词向量bert、GPT等，他们共有的特点是输入词语（不是数值），内部自行训练出对每个词的映射向量

